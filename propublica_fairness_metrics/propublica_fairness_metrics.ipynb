{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# source: https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm\n",
    "data = [[\"black\", 0, 0, 990],\n",
    "[\"black\", 0, 1, 805],\n",
    "[\"black\", 1, 0, 532],\n",
    "[\"black\", 1, 1, 1369],\n",
    "[\"white\", 0, 0, 1139],\n",
    "[\"white\", 0, 1, 349],\n",
    "[\"white\", 1, 0, 461],\n",
    "[\"white\", 1, 1, 505]]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"race\", \"outcome\", \"prediction\", \"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness in ProPublica's \"Machine Bias\"\n",
    "\n",
    "An illustration of incompatable fairness metrics on the ProPublia [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing). COMPAS is shown to have equal accuracy and calibration for white and black subgroups, but very unequal false positive rates.\n",
    "\n",
    "Later work showed that accuracy, calibration, and false positive rates cannot be equal if the base rates are unequal.\n",
    "\n",
    "### Data\n",
    "\n",
    "Provided in a [methodology piece](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm) accompanying the original article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot tables\n",
    "\n",
    "White parolees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outcome</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1139</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction     0    1\n",
       "outcome              \n",
       "0           1139  349\n",
       "1            461  505"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table( df[df[\"race\"]==\"white\"], values=\"count\", index=\"outcome\", columns=\"prediction\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black parolees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outcome</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>990</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>532</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction    0     1\n",
       "outcome              \n",
       "0           990   805\n",
       "1           532  1369"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table( df[df[\"race\"]==\"black\"], values=\"count\", index=\"outcome\", columns=\"prediction\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "What fraction of the time did COMPAS get it right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct predictions:  4003\n"
     ]
    }
   ],
   "source": [
    "total_correct_predictions = df[df.outcome==df.prediction][\"count\"].sum()\n",
    "print( \"Total correct predictions: \", total_correct_predictions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions:  6150\n"
     ]
    }
   ],
   "source": [
    "total = df[\"count\"].sum()\n",
    "print( \"Total predictions: \", total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.09%\n"
     ]
    }
   ],
   "source": [
    "accuracy = total_correct_predictions / total\n",
    "print( f\"Accuracy: {accuracy*100:0.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_white = df[df[\"race\"]==\"white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct predictions, white:  1644\n"
     ]
    }
   ],
   "source": [
    "total_correct_predictions_white = df_white[df_white.outcome==df_white.prediction][\"count\"].sum()\n",
    "print( \"Total correct predictions, white: \", total_correct_predictions_white )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions, white:  2454\n"
     ]
    }
   ],
   "source": [
    "total_white = df_white[\"count\"].sum()\n",
    "print( \"Total predictions, white: \", total_white )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, white: 66.99%\n"
     ]
    }
   ],
   "source": [
    "accuracy_white = total_correct_predictions_white / total_white\n",
    "print( f\"Accuracy, white: {accuracy_white*100:0.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_black = df[df[\"race\"]==\"black\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct predictions, black:  2359\n"
     ]
    }
   ],
   "source": [
    "total_correct_predictions_black = df_black[df_black.outcome==df_black.prediction][\"count\"].sum()\n",
    "print( \"Total correct predictions, black: \", total_correct_predictions_black )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions, black:  3696\n"
     ]
    }
   ],
   "source": [
    "total_black = df_black[\"count\"].sum()\n",
    "print( \"Total predictions, black: \", total_black )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, black: 63.83%\n"
     ]
    }
   ],
   "source": [
    "accuracy_black = total_correct_predictions_black / total_black\n",
    "print( f\"Accuracy, black: {accuracy_black*100:0.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for black and white subgroups are comparable; though the accuracy is a few points higher for the white subgroup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration across groups; meaning of a positive prediction\n",
    "\n",
    "What is the score meaning? Is it different for different groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chance of recidivism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recidivate = df[df[\"outcome\"]==1][\"count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall chance of recidivating: 131.88%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall chance of recidivating: {100*total_recidivate / total:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of recidivating for positive prediction (ie, meaning of positive prediction), overall: 61.89%\n"
     ]
    }
   ],
   "source": [
    "df_pred_pos = df[df[\"prediction\"]==1]\n",
    "df_pred_pos_total = df_pred_pos[\"count\"].sum()\n",
    "df_pred_pos_true = df_pred_pos[ df_pred_pos[\"outcome\"]==1 ][\"count\"].sum()\n",
    "\n",
    "print( f\"Chance of recidivating for positive prediction (ie, meaning of positive prediction), overall: {100*df_pred_pos_true / df_pred_pos_total:0.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>outcome</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    race  outcome  prediction  count\n",
       "5  white        0           1    349\n",
       "7  white        1           1    505"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp = df[ ((df[\"race\"]==\"white\") & (df[\"prediction\"]==1)) ]\n",
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = dfp[\"count\"].sum()\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_pos = dfp[dfp[\"outcome\"]==1].iloc[0][\"count\"]\n",
    "true_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meaning of positive prediction, white subgroup: 59.1% recidivism\n"
     ]
    }
   ],
   "source": [
    "print( f\"Meaning of positive prediction, white subgroup: {100*true_pos/total:0.1f}% recidivism\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>outcome</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    race  outcome  prediction  count\n",
       "1  black        0           1    805\n",
       "3  black        1           1   1369"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp = df[ ((df[\"race\"]==\"black\") & (df[\"prediction\"]==1)) ]\n",
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2174"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = dfp[\"count\"].sum()\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_pos = dfp[dfp[\"outcome\"]==1].iloc[0][\"count\"]\n",
    "true_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meaning of positive prediction, black subgroup: 63.0% recidivism\n"
     ]
    }
   ],
   "source": [
    "print( f\"Meaning of positive prediction, black subgroup: {100*true_pos/total:0.1f}% recidivism\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of a positive prediction is within a few points for each subgroup; each subgroup is calibrated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meaning of a negative prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of recidivating for negative prediction (ie, meaning of negative prediction), overall: 31.8% recidivism\n"
     ]
    }
   ],
   "source": [
    "df_pred_neg = df[df[\"prediction\"]==0]\n",
    "df_pred_neg_total = df_pred_neg[\"count\"].sum()\n",
    "df_pred_neg_true = df_pred_neg[ df_pred_neg[\"outcome\"]==1 ][\"count\"].sum()\n",
    "\n",
    "print( f\"Chance of recidivating for negative prediction (ie, meaning of negative prediction), overall: {100*df_pred_neg_true / df_pred_neg_total:0.1f}% recidivism\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chance of being wrongly predicted high-risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>outcome</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    race  outcome  prediction  count\n",
       "4  white        0           0   1139\n",
       "5  white        0           1    349\n",
       "6  white        1           0    461\n",
       "7  white        1           1    505"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp = df[ (df[\"race\"]==\"white\") ]\n",
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = dfp[(dfp[\"outcome\"]==0) & (dfp[\"prediction\"]==0)].iloc[0][\"count\"]\n",
    "FN = dfp[(dfp[\"outcome\"]==1) & (dfp[\"prediction\"]==0)].iloc[0][\"count\"]\n",
    "TP = dfp[(dfp[\"outcome\"]==1) & (dfp[\"prediction\"]==1)].iloc[0][\"count\"]\n",
    "FP = dfp[(dfp[\"outcome\"]==0) & (dfp[\"prediction\"]==1)].iloc[0][\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neg = FP+TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of being wrongly predicted high-risk when not recidivating, white: 23.5%\n"
     ]
    }
   ],
   "source": [
    "print( f\"Chance of being wrongly predicted high-risk when not recidivating, white: {100*FP/all_neg:0.1f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>outcome</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    race  outcome  prediction  count\n",
       "0  black        0           0    990\n",
       "1  black        0           1    805\n",
       "2  black        1           0    532\n",
       "3  black        1           1   1369"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp = df[ (df[\"race\"]==\"black\") ]\n",
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = dfp[(dfp[\"outcome\"]==0) & (dfp[\"prediction\"]==0)].iloc[0][\"count\"]\n",
    "FN = dfp[(dfp[\"outcome\"]==1) & (dfp[\"prediction\"]==0)].iloc[0][\"count\"]\n",
    "TP = dfp[(dfp[\"outcome\"]==1) & (dfp[\"prediction\"]==1)].iloc[0][\"count\"]\n",
    "FP = dfp[(dfp[\"outcome\"]==0) & (dfp[\"prediction\"]==1)].iloc[0][\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of being wrongly predicted high-risk when not recidivating, black: 54.1%\n"
     ]
    }
   ],
   "source": [
    "print( f\"Chance of being wrongly predicted high-risk when not recidivating, black: {100*FP/all_neg:0.1f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: unequal base rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recidivism is higher in the black subgroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5143398268398268"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"race\"] == \"black\") & (df[\"outcome\"] == 1)][\"count\"].sum() / df[(df[\"race\"] == \"black\")][\"count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39364303178484106"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"race\"] == \"white\") & (df[\"outcome\"] == 1)][\"count\"].sum() / df[(df[\"race\"] == \"white\")][\"count\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is impossible to equalize accuracy, calibration, and false positive rate at the same time if base rates are not equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In face, base rates are unequal because recidivism is a consequence of poverty, which is disproportionately effects Black people in the United States as an ongoing legacy of slavery and racialized classism.\n",
    "\n",
    "There is no magical mathematical wand to undo a crime; algorithms will always be unfair as long as society is unfair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
